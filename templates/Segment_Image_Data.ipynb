{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook to format your data for segmentation, run the images through the cloud instance of DeepCell, and then extract marker counts and morphological information from all the cells in your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'twisted'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-002d7ad3f7bb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdata_utils\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mload_utils\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mio_utils\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdeepcell_service_utils\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msegmentation_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msegmentation\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmarker_quantification\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ark-analysis\\ark\\utils\\deepcell_service_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mark\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mio_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtwisted\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minternet\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mreactor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkiosk_client\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmanager\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mglob\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'twisted'"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from ark.utils import data_utils, load_utils, io_utils, deepcell_service_utils, segmentation_utils\n",
    "from ark.segmentation import marker_quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "base_dir = \"../data/example_dataset\"\n",
    "input_dir = os.path.join(base_dir, \"input_data\")\n",
    "tiff_dir = os.path.join(input_dir, \"single_channel_inputs/\")\n",
    "deepcell_input_dir = os.path.join(input_dir, \"deepcell_input/\")\n",
    "deepcell_output_dir = os.path.join(base_dir, 'deepcell_output')\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "label_dir = os.path.join(base_dir, 'deepcell_output')\n",
    "viz_dir = os.path.join(base_dir, \"deepcell_visualization\")\n",
    "\n",
    "# create directories if do not exist\n",
    "for directory in [deepcell_input_dir, deepcell_output_dir, single_cell_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are using the example data located in /data/example_dataset/input_data. To modify this notebook to run using your own data, simply change the base_dir to point to your own sub-directory within the data folder, rather than 'example_dataset'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to true for multi-channel tiffs\n",
    "MIBItiff = False\n",
    "\n",
    "# data file suffix for low-level processed data\n",
    "# only needed for MIBItiff = True\n",
    "MIBItiff_suffix = \"-MassCorrected-Filtered.tiff\"\n",
    "\n",
    "# nuclear channel name(s) (or nucs = None)\n",
    "nucs = ['HH3']\n",
    "\n",
    "# membrane channel name(s) (or mems = None)\n",
    "mems = ['Membrane']\n",
    "\n",
    "# validate paths\n",
    "io_utils.validate_paths([base_dir,\n",
    "                         input_dir,\n",
    "                         tiff_dir,\n",
    "                         deepcell_input_dir,\n",
    "                         deepcell_output_dir,\n",
    "                         single_cell_dir\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute and filter fov paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "if MIBItiff:\n",
    "    fovs = io_utils.list_files(tiff_dir, substrs=MIBItiff_suffix)\n",
    "else:\n",
    "    fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov1\", \"fov2\"]\n",
    "\n",
    "# TODO: MIBItiff manual selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load images into notebook, process, and save as deepcell compatable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load channels to be included in deepcell data\n",
    "channels = (nucs if nucs else []) + (mems if mems else [])\n",
    "\n",
    "# filter channels for None (just in case)\n",
    "channels = [channel for channel in channels if channel is not None]\n",
    "\n",
    "if MIBItiff:\n",
    "    data_xr = load_utils.load_imgs_from_mibitiff(tiff_dir, mibitiff_files=fovs, channels=channels)\n",
    "else:\n",
    "    data_xr = load_utils.load_imgs_from_tree(tiff_dir, img_sub_folder=\"TIFs\", fovs=fovs, channels=channels)\n",
    "\n",
    "# generate and save deepcell input tifs\n",
    "data_utils.generate_deepcell_input(data_xr, deepcell_input_dir, nucs, mems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files to Deepcell and download results\n",
    "\n",
    "Deepcell input images will be zipped into a single file, uploaded to [deepcell.org](https://deepcell.org),\n",
    "\n",
    "and the output will be downloaded to the deepcell output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepcell_service_utils.create_deepcell_output(deepcell_input_dir, deepcell_output_dir, fovs=fovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then load the segmented mask from deepcell via label-map TIFFs and save as an xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segmentation_labels = load_utils.load_imgs_from_dir(data_dir=label_dir,\n",
    "                                                    imgdim_name='compartments',\n",
    "                                                    image_name='whole_cell',\n",
    "                                                    delimiter='_feature_0',\n",
    "                                                    force_ints=True)\n",
    "\n",
    "\n",
    "save_name = os.path.join(label_dir, 'segmentation_labels.xr')\n",
    "if os.path.exists(save_name):\n",
    "    print(\"overwriting previously generated processed output file\")\n",
    "    os.remove(save_name)\n",
    "\n",
    "segmentation_labels.to_netcdf(save_name, format=\"NETCDF3_64BIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We can also then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if fovs is None or fovs == []:\n",
    "    fovs_input = io_utils.list_files(deepcell_input_dir, substrs=['tif'])\n",
    "else:\n",
    "    fovs_input = io_utils.list_files(deepcell_input_dir, substrs=fovs)\n",
    "\n",
    "# Both channels and Point8\n",
    "\n",
    "# Get input for overlay\n",
    "input_data_xr = load_utils.load_imgs_from_multitiff(deepcell_input_dir,\n",
    "                                                    multitiff_files=fovs_input)\n",
    "# Overlaying the DNA\n",
    "overlay_channels = input_data_xr.channels.values\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Channel 0 and Point 8\n",
    "segmentation_utils.visualize_segmentation(\n",
    "            segmentation_labels_xr=segmentation_labels,\n",
    "            fovs=input_data_xr[:,:,:,0].fovs.values, channel_data_xr=input_data_xr,\n",
    "            chan_list = overlay_channels[0], output_dir=viz_dir, show=True)\n",
    "\n",
    "chan_list = overlay_channels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each FOV given it's own folder and all FOVs having the same channels\n",
    "combined_cell_size_normalized_data, combined_arcsinh_transformed_data = \\\n",
    "    marker_quantification.generate_cell_data(segmentation_labels=segmentation_labels,\n",
    "                                             tiff_dir=tiff_dir,\n",
    "                                             img_sub_folder=\"TIFs\",\n",
    "                                             is_mibitiff=MIBItiff,\n",
    "                                             fovs=fovs,\n",
    "                                             batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path to the single_cell_output folder, and create it if it doesn't already exist\n",
    "# this is where we will store our combined_normalized_data and combined_transformed_data output\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "\n",
    "if not os.path.exists(single_cell_dir):\n",
    "    os.makedirs(single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path to the single_cell_output folder, and create it if it doesn't already exist\n",
    "# this is where we will store our combined_normalized_data and combined_transformed_data output\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "\n",
    "if not os.path.exists(single_cell_dir):\n",
    "    os.makedirs(single_cell_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}