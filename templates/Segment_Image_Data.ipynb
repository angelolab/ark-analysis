{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook to format your data for segmentation, run the images through the cloud instance of DeepCell, and then extract marker counts and morphological information from all the cells in your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ark.utils import data_utils, load_utils, io_utils, plot_utils, deepcell_service_utils\n",
    "from ark.segmentation import marker_quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "base_dir = \"../data/example_dataset\"\n",
    "input_dir = os.path.join(base_dir, \"input_data\")\n",
    "tiff_dir = os.path.join(input_dir, \"single_channel_inputs/\")\n",
    "deepcell_input_dir = os.path.join(input_dir, \"deepcell_input/\")\n",
    "deepcell_output_dir = os.path.join(base_dir, 'deepcell_output')\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "\n",
    "# create directories if do not exist\n",
    "for directory in [deepcell_input_dir, deepcell_output_dir, single_cell_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are using the example data located in /data/example_dataset/input_data. To modify this notebook to run using your own data, simply change the base_dir to point to your own sub-directory within the data folder, rather than 'example_dataset'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to true for multi-channel tiffs\n",
    "MIBItiff = False\n",
    "\n",
    "# data file suffix for low-level processed data\n",
    "# only needed for MIBItiff = True\n",
    "MIBItiff_suffix = \"-MassCorrected-Filtered.tiff\"\n",
    "\n",
    "# nuclear channel name(s) (or nucs = None)\n",
    "nucs = ['HH3']\n",
    "\n",
    "# membrane channel name(s) (or mems = None)\n",
    "mems = ['Membrane']\n",
    "\n",
    "# validate paths\n",
    "io_utils.validate_paths([base_dir,\n",
    "                         input_dir,\n",
    "                         tiff_dir,\n",
    "                         deepcell_input_dir,\n",
    "                         deepcell_output_dir,\n",
    "                         single_cell_dir\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute and filter fov paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "if MIBItiff:\n",
    "    fovs = io_utils.list_files(tiff_dir, substrs=MIBItiff_suffix)\n",
    "else:\n",
    "    fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov1\", \"fov2\"]\n",
    "\n",
    "# TODO: MIBItiff manual selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load images into notebook, process, and save as deepcell compatable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ark/utils/data_utils.py:41: UserWarning: ../data/example_dataset/input_data/deepcell_input/fov8.tif is a low contrast image\n",
      "  io.imsave(save_path, out, plugin='tifffile')\n"
     ]
    }
   ],
   "source": [
    "# load channels to be included in deepcell data\n",
    "channels = (nucs if nucs else []) + (mems if mems else [])\n",
    "\n",
    "# filter channels for None (just in case)\n",
    "channels = [channel for channel in channels if channel is not None]\n",
    "\n",
    "if MIBItiff:\n",
    "    data_xr = load_utils.load_imgs_from_mibitiff(tiff_dir, mibitiff_files=fovs, channels=channels)\n",
    "else:\n",
    "    data_xr = load_utils.load_imgs_from_tree(tiff_dir, img_sub_folder=\"TIFs\", fovs=fovs, channels=channels)\n",
    "\n",
    "# generate and save deepcell input tifs\n",
    "data_utils.generate_deepcell_input(data_xr, deepcell_input_dir, nucs, mems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files to Deepcell and download results\n",
    "\n",
    "Deepcell input images will be zipped into a single file, uploaded to [deepcell.org](https://deepcell.org),\n",
    "\n",
    "and the output will be downloaded to the deepcell output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepcell_service_utils.create_deepcell_output(deepcell_input_dir, deepcell_output_dir, fovs=fovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then load the segmented mask from deepcell via label-map TIFFs and save as an xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ark/utils/load_utils.py:270: UserWarning: The loaded float32 images were forcefully overwritten with the supplied integer dtype int16\n",
      "  warnings.warn(f\"The loaded {data_dtype} images were forcefully \"\n"
     ]
    }
   ],
   "source": [
    "segmentation_labels = load_utils.load_imgs_from_dir(data_dir=deepcell_output_dir,\n",
    "                                                    xr_dim_name='compartments',\n",
    "                                                    xr_channel_names=['whole_cell'],\n",
    "                                                    delimiter='_feature_0',\n",
    "                                                    force_ints=True)\n",
    "\n",
    "save_name = os.path.join(deepcell_output_dir, 'segmentation_labels.xr')\n",
    "if os.path.exists(save_name):\n",
    "    print(\"overwriting previously generated processed output file\")\n",
    "    os.remove(save_name)\n",
    "\n",
    "segmentation_labels.to_netcdf(save_name, format=\"NETCDF3_64BIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We can also then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xr_summed = load_utils.load_imgs_from_dir(data_dir=deepcell_input_dir,\n",
    "                                               files=[fov + '.tif' for fov in data_xr.coords['fovs'].values],\n",
    "                                               xr_dim_name='compartments',\n",
    "                                               xr_channel_names=data_xr.coords['channels'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for fov in data_xr.fovs:\n",
    "    plot_utils.plot_overlay(segmentation_labels.loc[fov, :, :, \"whole_cell\"].values,\n",
    "                            data_xr_summed.loc[fov, :, :, :].values,\n",
    "                            path=os.path.join(deepcell_output_dir, f'{fov.values}_overlay.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data from fov8\n"
     ]
    }
   ],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given its own folder and all fovs having the same channels\n",
    "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "    marker_quantification.generate_cell_table(segmentation_labels=segmentation_labels,\n",
    "                                             tiff_dir=tiff_dir,\n",
    "                                             img_sub_folder=\"TIFs\",\n",
    "                                             is_mibitiff=MIBItiff,\n",
    "                                             fovs=fovs,\n",
    "                                             batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save extracted data as csv for downstream analysis\n",
    "cell_table_size_normalized.to_csv(os.path.join(single_cell_dir, 'cell_table_size_normalized.csv'),\n",
    "                                 index=False)\n",
    "cell_table_arcsinh_transformed.to_csv(os.path.join(single_cell_dir, 'cell_table_arcsinh_transformed.csv'),\n",
    "                                     index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
