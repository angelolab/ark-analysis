{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook to run the preprocessing pipeline, upload files to DeepCell and download output, processes it, segments cells, and extract channel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ark.utils import data_utils, load_utils, io_utils, plot_utils, deepcell_service_utils\n",
    "from ark.segmentation import marker_quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff0000\"> All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data' regardless of if it's input or output. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "base_dir = \"../data/example_dataset\"\n",
    "input_dir = os.path.join(base_dir, \"input_data\")\n",
    "tiff_dir = os.path.join(input_dir, \"single_channel_inputs/\")\n",
    "deepcell_input_dir = os.path.join(input_dir, \"deepcell_input/\")\n",
    "deepcell_output_dir = os.path.join(base_dir, 'deepcell_output')\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "\n",
    "# create directories if do not exist\n",
    "for directory in [deepcell_input_dir, deepcell_output_dir, single_cell_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "# set this to true for multi-channel tiffs\n",
    "MIBItiff = False\n",
    "\n",
    "# data file suffix for low-level processed data\n",
    "# only needed for MIBItiff = True\n",
    "MIBItiff_suffix = \"-MassCorrected-Filtered.tiff\"\n",
    "\n",
    "# nuclear channel name(s) (or nucs = None)\n",
    "nucs = ['HH3']\n",
    "\n",
    "# membrane channel name(s) (or mems = None)\n",
    "mems = ['Membrane']\n",
    "\n",
    "# validate paths\n",
    "io_utils.validate_paths([base_dir,\n",
    "                         input_dir,\n",
    "                         tiff_dir,\n",
    "                         deepcell_input_dir,\n",
    "                         deepcell_output_dir,\n",
    "                         single_cell_dir\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute and filter fov paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "if MIBItiff:\n",
    "    fovs = io_utils.list_files(tiff_dir, substrs=MIBItiff_suffix)\n",
    "else:\n",
    "    fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov1\", \"fov2\"]\n",
    "\n",
    "# TODO: MIBItiff manual selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load images into notebook, process, and save as deepcell compatable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load channels to be included in deepcell data\n",
    "channels = (nucs if nucs else []) + (mems if mems else [])\n",
    "\n",
    "# filter channels for None (just in case)\n",
    "channels = [channel for channel in channels if channel is not None]\n",
    "\n",
    "if MIBItiff:\n",
    "    data_xr = load_utils.load_imgs_from_mibitiff(tiff_dir, mibitiff_files=fovs, channels=channels)\n",
    "else:\n",
    "    data_xr = load_utils.load_imgs_from_tree(tiff_dir, img_sub_folder=\"TIFs\", fovs=fovs, channels=channels)\n",
    "\n",
    "# generate and save deepcell input tifs\n",
    "data_utils.generate_deepcell_input(data_xr, deepcell_input_dir, nucs, mems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files to Deepcell and download results\n",
    "\n",
    "Deepcell input images will be zipped into a single file, uploaded to [deepcell.org](https://deepcell.org),\n",
    "\n",
    "and the output will be downloaded to the deepcell output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepcell_service_utils.create_deepcell_output(deepcell_input_dir, deepcell_output_dir, fovs=fovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then load the segmented mask from deepcell via label-map TIFFs and save as an xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segmentation_labels = load_utils.load_imgs_from_dir(data_dir=deepcell_output_dir,\n",
    "                                                    imgdim_name='compartments',\n",
    "                                                    channels=['whole_cell'],\n",
    "                                                    delimiter='_feature_0',\n",
    "                                                    force_ints=True)\n",
    "\n",
    "save_name = os.path.join(deepcell_output_dir, 'segmentation_labels.xr')\n",
    "if os.path.exists(save_name):\n",
    "    print(\"overwriting previously generated processed output file\")\n",
    "    os.remove(save_name)\n",
    "\n",
    "segmentation_labels.to_netcdf(save_name, format=\"NETCDF3_64BIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We can also then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for fov in data_xr.fovs:\n",
    "    plot_utils.plot_overlay(segmentation_labels.loc[fov, :, :, \"whole_cell\"].values,\n",
    "                            data_xr.loc[fov, :, :, :].values,\n",
    "                            path=os.path.join(deepcell_output_dir, f'{fov.values}_overlay.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given it's own folder and all fovs having the same channels\n",
    "combined_cell_size_normalized_data, combined_arcsinh_transformed_data = \\\n",
    "    marker_quantification.generate_cell_data(segmentation_labels=segmentation_labels,\n",
    "                                             tiff_dir=tiff_dir,\n",
    "                                             img_sub_folder=\"TIFs\",\n",
    "                                             is_mibitiff=MIBItiff,\n",
    "                                             fovs=fovs,\n",
    "                                             batch_size=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}