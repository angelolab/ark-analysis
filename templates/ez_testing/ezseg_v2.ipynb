{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ezSegmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This segmentation tool enables creation of masks for objects not easily picked up by primary cell segmentation methods on multiplexed imaging data.\n",
    "#### In addition this tool can be used to create composites of channels as well as merge object masks with cell masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Set root directory and download example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder.\n",
    "\n",
    "* `base_dir`: the path to all of your imaging data. This directory will contain all of the data generated by this notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from ark.segmentation import ez_object_segmentation, ez_seg_display, merge_masks, composite_builder\n",
    "from alpineer import load_utils\n",
    "from tqdm.notebook import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = \"../data/example_dataset\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you would like to test the features in Ark with an example dataset, run the cell below. It will download a dataset consisting of 11 FOVs with 22 channels. You may find more information about the example dataset in the [README](../README.md#example-dataset).\n",
    "\n",
    "If you are using your own data, skip the cell below.\n",
    "\n",
    "* `overwrite_existing`: If set to `False`, it will not overwrite existing data in the `data/example_dataset`. Recommended leaving as `True` if you are doing a clean run of the `ark` pipeline using this dataset from the start. If you already have the dataset downloaded, set to `False`."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1597694138.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    If you would like to test the features in Ark with an example dataset, run the cell below. It will download a dataset consisting of 11 FOVs with 22 channels. You may find more information about the example dataset in the [README](../README.md#example-dataset).\u001B[0m\n\u001B[0m       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_dataset.get_example_dataset(dataset=\"ez_segment_image_data\", save_dir = base_dir, overwrite_existing = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1: set file paths and parameters\n",
    "\n",
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n",
    "\n",
    "If you're interested in directly interfacing with Google Drive, consult the documentation [here](https://ark-analysis.readthedocs.io/en/latest/_rtd/google_docs_usage.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
    "ez_table_dir = os.path.join(base_dir, \"segmentation/ez_table\")\n",
    "ez_input_dir = os.path.join(base_dir, \"segmentation/ez_input\")\n",
    "ez_output_dir = os.path.join(base_dir, \"segmentation/ez_output\")\n",
    "ez_visualization_dir = os.path.join(base_dir, \"segmentation/ez_visualization\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create directories if do not exist\n",
    "for directory in [ez_table_dir, ez_input_dir, ez_output_dir, ez_visualization_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# validate paths\n",
    "io_utils.validate_paths([base_dir,\n",
    "                         tiff_dir,\n",
    "                         ez_input_dir,\n",
    "                         ez_output_dir,\n",
    "                         ez_table_dir,\n",
    "                         ez_visualization_dir\n",
    "                         ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute and filter fov paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov0\", \"fov1\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Composite Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set composite paths, test FoV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give path names for where composite images should be stored\n",
    "composite_directory = \"../../data/experiments/ezSeg Data/Composites/Point77/\"\n",
    "# What would you like to name your composite image\n",
    "composite_name = \"composite_a.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# What channels would you like to add together?\n",
    "to_add = [\"8OHGuano\", \"C12\", \"Reelin\"]\n",
    "# What channels would you like to subtract?\n",
    "to_subtract = [\"MBP\", \"Iba1\", \"Si28\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create your composite channel.\n",
    "Specify image_type (\"signal\" or \"pixel_clustered\"), and composite_method (\"total\" or \"binary\") below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run composite builder\n",
    "composite_array = composite_builder.composite_builder(\n",
    "    data=object_masks,\n",
    "    images_to_add=to_add,\n",
    "    images_to_subtract=to_subtract,\n",
    "    composite_name = composite_name,\n",
    "    composite_directory=composite_directory,\n",
    "    image_type=\"signal\",\n",
    "    composite_method=\"total\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify which FoV you'd like to see for visual testing purposes.\n",
    "test_FoV_name = \"\"\n",
    "composite_test_image = \"\" # this should take the base path from earlier, the composite path, the test FoV name, and the composite name without user input.\n",
    "# Show test composite image\n",
    "ez_seg_display.display_channel_image(composite_test_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Create Object Masks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create your object segmentation masks.\n",
    "Here you will input which channel you would like as a base for segmenting single object masks.\n",
    "\n",
    "Additionally, set segmentation parameters below, including: object type, blur, threshold, smallest hole size allowed, fov size (one side, in um),\n",
    "and minimum & maximum object areas of the object masks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Name the channel you want to segment on.\n",
    "channel_to_segment = \"\"\n",
    "################################# need to pull the channel from the xarray. Alternatively need to only load test images and run on all afterwards.\n",
    "# object shape (blur or projection)\n",
    "object_shape = \"blob\"\n",
    "# blurring value\n",
    "blur = \"1\"\n",
    "# signal value to start mask creation on. None defaults to a local thresholding value.\n",
    "threshold = None\n",
    "# any holes above the hole_size value will be filled in objects. None defaults to a hole size value based on the fov and number of pixels.\n",
    "hole_size = None\n",
    "# the length of one side of your fov in um.\n",
    "fov_size = 400\n",
    "# minimum number of pixels required in a segmented object\n",
    "min_pixels = 100\n",
    "# maximum number of pixels required in a segmented object\n",
    "max_pixels = 100000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Input parameters and segment images.\n",
    "create_object_masks(\n",
    "    input_image: np.ndarray,\n",
    "    object_shape_type: str = object_shape,\n",
    "    sigma: int = blur,\n",
    "    thresh: Optional[np.float32] = None,\n",
    "    hole_size: Optional[int] = None,\n",
    "    fov_dim: int = 400,\n",
    "    min_object_area: int = 100,\n",
    "    max_object_area: int = 100000,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify which segmented FoV you'd like to see for visual testing purposes.\n",
    "test_FoV_name = \"\"\n",
    "ez_seg_test_masks = \"\" # this should take the base path from earlier, the composite path, the test FoV name, and the composite name without user input.\n",
    "# Show test composite image\n",
    "ez_seg_display.overlay_mask_outlines(channel_to_segment, ez_seg_test_masks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mask Merger\n",
    "\n",
    "Merging enables connecting traditional circular or oval shaped nucelar-based cell masks with anuclear cell projections (e.g. microglia arms with microglia soma)\n",
    "**Note:** Requires the Deepcell outputs from `1_Segment_Image_Data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Here you can merge object segmentation masks with cell masks (or any other type of mask).\n",
    "Here you will provide a list of what objects you would like to merge with previously segmented cell masks (or other base mask).\n",
    "\n",
    "**LIST ORDER IMPORTANT**: The first mask listed will be merged first, the second mask with cells not merged during the first merge, etc.\n",
    "\n",
    "Additionally, set the percent area of an object that needs to be overlapping onto a cell mask to get merged."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input path\n",
    "curr_object_mask = pathlib.Path(\"../../data/experiments/ezSeg Data/segmentation/deepcell_output/TIFs_whole_cell.tiff\")\n",
    "# List of object masks to merge to the base (cell) image.\n",
    "merge_masks_list = [\"microglia-arms\", \"astrocyte-arms\", \"neuropil\"]\n",
    "# Value (1-100) required for an object mask to be merged into a cell mask.\n",
    "percent_overlap = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decide here if you want a single mask combining all cells and objects found in merge_mask_list (True) or a merged mask saved for each cell and object type (False).\n",
    "fully_combined_masks = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_masks.merge_masks_seq(\n",
    "    object_list=[\"composite_b\", \"composite_a\"],\n",
    "    object_mask_dir=ez_directory,\n",
    "    cell_mask_path=curr_object_mask,\n",
    "    overlap=percent_overlap,\n",
    "    save_path=composite_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Specify which segmented FoV you'd like to see for visual testing purposes.\n",
    "test_FoV_name = \"\"\n",
    "ez_seg_test_masks = \"\" # this should take the base path from earlier, the composite path, the test FoV name, and the composite name without user input.\n",
    "# Show test composite image\n",
    "ez_seg_display.multiple_mask_displays(merge_masks_list, cell_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Generate single cell and/or object expression table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set to True to bypass expensive cell or object property calculations\n",
    "# only cell or object label, size, and centroid will be extracted if True\n",
    "fast_extraction = False\n",
    "\n",
    "# If you want to give your cell label an alternative name (e.g. plaques.csv), write that name below, otherwise leave as \"cell\".\n",
    "table_name = \"cell\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a full list of features extracted, please refer to the cell table section of: https://ark-analysis.readthedocs.io/en/latest/_rtd/data_types.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given its own folder and all fovs having the same channels\n",
    "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "    marker_quantification.generate_cell_table(segmentation_dir=deepcell_output_dir,\n",
    "                                              tiff_dir=tiff_dir,\n",
    "                                              img_sub_folder=None,\n",
    "                                              fovs=fovs,\n",
    "                                              batch_size=5,\n",
    "                                              nuclear_counts=nuclear_counts,\n",
    "                                              fast_extraction=fast_extraction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the compression level if desired, ZSTD compression can offer up to a 60-70% reduction in file size.\n",
    "# NOTE: Compressed `csv` files cannot be opened in Excel. They must be uncompressed beforehand.\n",
    "compression = None\n",
    "\n",
    "# Uncomment the line below to allow for compressed `csv` files.\n",
    "# compression = {\"method\": \"zstd\", \"level\": 3}\n",
    "\n",
    "cell_table_size_normalized.to_csv(os.path.join(cell_table_dir, table_name + '_table_size_normalized.csv'),\n",
    "                                  compression=compression, index=False)\n",
    "cell_table_arcsinh_transformed.to_csv(os.path.join(cell_table_dir, table_name + '_table_arcsinh_transformed.csv'),\n",
    "                                      compression=compression, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## End - Cell &| Object Masks and Table have been saved"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
