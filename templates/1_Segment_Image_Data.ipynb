{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook to format your data for segmentation, run the images through the cloud instance of Mesmer, and then extract marker counts and morphological information from all the cells in your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "import"
    ]
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import xarray as xr\n",
    "from alpineer import io_utils\n",
    "\n",
    "from ark.segmentation import marker_quantification, segmentation_utils\n",
    "from ark.utils import (deepcell_service_utils, example_dataset,\n",
    "                       plot_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Set root directory and download example dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder.\n",
    "\n",
    "* `base_dir`: the path to all of your imaging data. This directory will contain all of the data generated by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "base_dir"
    ]
   },
   "outputs": [],
   "source": [
    "# set up the base directory\n",
    "base_dir = \"../data/example_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to test the features in Ark with an example dataset, run the cell below. It will download a dataset consisting of 11 FOVs with 22 channels. You may find more information about the example dataset in the [README](../README.md#example-dataset).\n",
    "\n",
    "If you are using your own data, skip the cell below.\n",
    "\n",
    "* `overwrite_existing`: If set to `False`, it will not overwrite existing data in the `data/example_dataset`. Recommended leaving as `True` if you are doing a clean run of the `ark` pipeline using this dataset from the start. If you already have the dataset downloaded, set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ex_data_download"
    ]
   },
   "outputs": [],
   "source": [
    "example_dataset.get_example_dataset(dataset=\"segment_image_data\", save_dir = base_dir, overwrite_existing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: set file paths and parameters\n",
    "\n",
    "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n",
    "\n",
    "If you're interested in directly interfacing with Google Drive, consult the documentation [here](https://ark-analysis.readthedocs.io/en/latest/_rtd/google_docs_usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "file_path"
    ]
   },
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
    "cell_table_dir = os.path.join(base_dir, \"segmentation/cell_table\")\n",
    "deepcell_input_dir = os.path.join(base_dir, \"segmentation/deepcell_input\")\n",
    "deepcell_output_dir = os.path.join(base_dir, \"segmentation/deepcell_output\")\n",
    "deepcell_visualization_dir = os.path.join(base_dir, \"segmentation/deepcell_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "create_dirs"
    ]
   },
   "outputs": [],
   "source": [
    "# create directories if do not exist\n",
    "for directory in [cell_table_dir, deepcell_input_dir, deepcell_output_dir, deepcell_visualization_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "validate_path"
    ]
   },
   "outputs": [],
   "source": [
    "# validate paths\n",
    "io_utils.validate_paths([base_dir,\n",
    "                         tiff_dir,\n",
    "                         deepcell_input_dir,\n",
    "                         deepcell_output_dir,\n",
    "                         cell_table_dir,\n",
    "                         deepcell_visualization_dir\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and filter fov paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "load_fovs"
    ]
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov0\", \"fov1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images into notebook, process, and save as Mesmer compatable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "nuc_mem_set"
    ]
   },
   "outputs": [],
   "source": [
    "# NOTE: at least one of nucs and mems must not be None\n",
    "# nuclear channel name(s) (or nucs = None)\n",
    "nucs = ['H3K9ac', 'H3K27me3']\n",
    "\n",
    "# membrane channel name(s) (or mems = None)\n",
    "mems = ['CD14', 'CD45', 'ECAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "gen_input"
    ]
   },
   "outputs": [],
   "source": [
    "# generate and save deepcell input tiffs\n",
    "# set img_sub_folder param to None if the image files in tiff_dir are not in a separate sub folder \n",
    "deepcell_service_utils.generate_deepcell_input(\n",
    "    deepcell_input_dir,\n",
    "    tiff_dir,\n",
    "    nucs,\n",
    "    mems,\n",
    "    fovs,\n",
    "    img_sub_folder=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Upload files to Deepcell and download results\n",
    "\n",
    "Deepcell input images will be zipped into a single file, uploaded to [deepcell.org](https://deepcell.org),\n",
    "\n",
    "and the output will be downloaded to the deepcell output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "seg_scale_set"
    ]
   },
   "outputs": [],
   "source": [
    "# Mesmer was trained on data acquired at 20X resolution. If your image data was acquired at a different resolution, you will get the best performance by rescaling. The rescale factor will increase or decrease the image resolution by the value you provide. For example, if you data was acquired at 10X, use a `rescale_factor` of 2. If your data was acquired at 60X resolution, use a `rescale_factor` of 0.33.\n",
    "rescale_factor = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "create_output"
    ]
   },
   "outputs": [],
   "source": [
    "deepcell_service_utils.create_deepcell_output(deepcell_input_dir, deepcell_output_dir, fovs=fovs, scale=rescale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We can then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "overlay_mask"
    ]
   },
   "outputs": [],
   "source": [
    "# display the channel overlay for a fov, useful for quick verification\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "fov_to_display = io_utils.remove_file_extensions([fovs[0]])[0]\n",
    "\n",
    "fov_overlay = plot_utils.create_overlay(\n",
    "    fov=fov_to_display,\n",
    "    segmentation_dir=deepcell_output_dir,\n",
    "    data_dir=deepcell_input_dir,\n",
    "    img_overlay_chans=['nuclear_channel', 'membrane_channel'],\n",
    "    seg_overlay_comp='whole_cell'\n",
    ")\n",
    "\n",
    "_ = io.imshow(fov_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save_mask"
    ]
   },
   "outputs": [],
   "source": [
    "# save the overlaid segmentation labels for each fov (these will not display, but will save in viz_dir)\n",
    "segmentation_utils.save_segmentation_labels(\n",
    "    segmentation_dir=deepcell_output_dir,\n",
    "    data_dir=deepcell_input_dir,\n",
    "    output_dir=deepcell_visualization_dir,\n",
    "    fovs=io_utils.remove_file_extensions(fovs),\n",
    "    channels=['nuclear_channel', 'membrane_channel']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nuc_props_set"
    ]
   },
   "outputs": [],
   "source": [
    "# set to True to add nuclear cell properties to the expression matrix\n",
    "nuclear_counts = False\n",
    "\n",
    "# set to True to bypass expensive cell property calculations\n",
    "# only cell label, size, and centroid will be extracted if True\n",
    "fast_extraction = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full list of features extracted, please refer to the cell table section of: https://ark-analysis.readthedocs.io/en/latest/_rtd/data_types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "create_exp_mat"
    ]
   },
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given its own folder and all fovs having the same channels\n",
    "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "    marker_quantification.generate_cell_table(segmentation_dir=deepcell_output_dir,\n",
    "                                              tiff_dir=tiff_dir,\n",
    "                                              img_sub_folder=None,\n",
    "                                              fovs=fovs,\n",
    "                                              batch_size=5,\n",
    "                                              nuclear_counts=nuclear_counts,\n",
    "                                              fast_extraction=fast_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save_exp_mat"
    ]
   },
   "outputs": [],
   "source": [
    "# Set the compression level if desired, ZSTD compression can offer up to a 60-70% reduction in file size.\n",
    "# NOTE: Compressed `csv` files cannot be opened in Excel. They must be uncompressed beforehand.\n",
    "compression = None\n",
    "\n",
    "# Uncomment the line below to allow for compressed `csv` files.\n",
    "# compression = {\"method\": \"zstd\", \"level\": 3}\n",
    "\n",
    "cell_table_size_normalized.to_csv(os.path.join(cell_table_dir, 'cell_table_size_normalized.csv'),\n",
    "                                  compression=compression, index=False)\n",
    "cell_table_arcsinh_transformed.to_csv(os.path.join(cell_table_dir, 'cell_table_arcsinh_transformed.csv'),\n",
    "                                      compression=compression, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cd428f2623867f362c6ffd1805d28fe273bb79d15f4a3a73107e7f51d98be79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
