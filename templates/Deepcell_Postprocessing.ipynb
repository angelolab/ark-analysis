{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook takes the output of deepcell, processes it, segments cells, and outputs the extracted channel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "\n",
    "from ark.utils import data_utils, plot_utils, io_utils\n",
    "from ark.segmentation import marker_quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "base_dir = \"../data/example_dataset\"\n",
    "input_dir = os.path.join(base_dir, \"input_data\")\n",
    "deepcell_input_dir = os.path.join(input_dir, 'deepcell_input')\n",
    "tiff_dir = os.path.join(input_dir, 'single_channel_inputs')\n",
    "label_dir = os.path.join(base_dir, 'deepcell_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to true if base images are MIBItiffs\n",
    "MIBItiff = False\n",
    "\n",
    "# points to look at (None for all)\n",
    "points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate file paths (add extra paths to this list)\n",
    "io_utils.validate_paths([\n",
    "    base_dir,\n",
    "    input_dir,\n",
    "    deepcell_input_dir,\n",
    "    tiff_dir,\n",
    "    label_dir,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We compute the paths for the deepcell input TIFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if points is None or points == []:\n",
    "    points_input = io_utils.list_files(deepcell_input_dir, substrs=['tif'])\n",
    "else:\n",
    "    points_input = io_utils.list_files(deepcell_input_dir, substrs=points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then load the segmented mask from deepcell via label-map TIFFs and save as an xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_labels = data_utils.load_imgs_from_dir(data_dir=label_dir,\n",
    "                                                    imgdim_name='compartments',\n",
    "                                                    image_name='whole_cell',\n",
    "                                                    delimiter='_feature_0',\n",
    "                                                    force_ints=True)\n",
    "\n",
    "save_name = os.path.join(label_dir, 'segmentation_labels.xr')\n",
    "if os.path.exists(save_name):\n",
    "    print(\"overwriting previously generated processed output file\")\n",
    "    os.remove(save_name)\n",
    "\n",
    "segmentation_labels.to_netcdf(save_name, format=\"NETCDF3_64BIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get input data for overlay\n",
    "input_data_xr = data_utils.load_imgs_from_multitiff(deepcell_input_dir, multitiff_files=points_input)\n",
    "\n",
    "for fov in input_data_xr.fovs:\n",
    "    plot_utils.plot_overlay(segmentation_labels.loc[fov, :, :, \"whole_cell\"].values,\n",
    "                            input_data_xr.loc[fov, :, :, :].values,\n",
    "                            path=os.path.join(label_dir, f'{fov.values}_overlay.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns:\n",
    "* cell_size_normalized_data: computed by dividing the marker counts in segmentation_labels by their corresponding cell size.\n",
    "* arcsinh_transformed_data: first, linearly scale each value of cell_size_normalized_data by multiplying by 100. Then, pass the linearly scaled cell_size_normalized_data through the arcsinh function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each FOV given it's own folder and all FOVs having the same channels\n",
    "combined_cell_size_normalized_data, combined_arcsinh_transformed_data = \\\n",
    "    marker_quantification.compute_complete_expression_matrices(segmentation_labels=segmentation_labels,\n",
    "                                                               tiff_dir=tiff_dir,\n",
    "                                                               img_sub_folder=\"TIFs\",\n",
    "                                                               is_mibitiff=MIBItiff,\n",
    "                                                               points=points,\n",
    "                                                               batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path to the single_cell_output folder, and create it if it doesn't already exist\n",
    "# this is where we will store our combined_normalized_data and combined_transformed_data output\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "\n",
    "if not os.path.exists(single_cell_dir):\n",
    "    os.makedirs(single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output as CSV\n",
    "combined_cell_size_normalized_data.to_csv(os.path.join(single_cell_dir, 'cell_size_normalized_data.csv'), index=False)\n",
    "combined_arcsinh_transformed_data.to_csv(os.path.join(single_cell_dir, 'arcsinh_transformed_data.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
