{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook takes the output of deepcell, processes it, segments cells, and outputs the extracted channel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\kevin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from ark.utils import load_utils, segmentation_utils, io_utils\n",
    "from ark.segmentation import marker_quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "base_dir = \"../data/example_dataset\"\n",
    "input_dir = os.path.join(base_dir, \"input_data\")\n",
    "deepcell_input_dir = os.path.join(input_dir, 'deepcell_input')\n",
    "tiff_dir = os.path.join(input_dir, 'single_channel_inputs')\n",
    "label_dir = os.path.join(base_dir, 'deepcell_output')\n",
    "viz_dir = os.path.join(base_dir, \"deepcell_visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# create viz_dir directory if it does not already exist\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.mkdir(viz_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to true if base images are MIBItiffs\n",
    "MIBItiff = False\n",
    "\n",
    "# fovs to look at (None for all)\n",
    "points = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate file paths (add extra paths to this list)\n",
    "io_utils.validate_paths([\n",
    "    base_dir,\n",
    "    input_dir,\n",
    "    deepcell_input_dir,\n",
    "    tiff_dir,\n",
    "    label_dir,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We compute the paths for the deepcell input TIFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if points is None or points == []:\n",
    "    points_input = io_utils.list_files(deepcell_input_dir, substrs=['tif'])\n",
    "else:\n",
    "    points_input = io_utils.list_files(deepcell_input_dir, substrs=points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then load the segmented mask from deepcell via label-map TIFFs and save as an xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwriting previously generated processed output file\n"
     ]
    }
   ],
   "source": [
    "segmentation_labels = load_utils.load_imgs_from_dir(data_dir=label_dir,\n",
    "                                                    imgdim_name='compartments',\n",
    "                                                    image_name='whole_cell',\n",
    "                                                    delimiter='_feature_0',\n",
    "                                                    force_ints=True)\n",
    "\n",
    "save_name = os.path.join(label_dir, 'segmentation_labels.xr')\n",
    "if os.path.exists(save_name):\n",
    "    print(\"overwriting previously generated processed output file\")\n",
    "    os.remove(save_name)\n",
    "\n",
    "segmentation_labels.to_netcdf(save_name, format=\"NETCDF3_64BIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also then save the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-e24242b413a3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# Get input for overlay\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m input_data_xr = load_utils.load_imgs_from_multitiff(deepcell_input_dir,\n\u001B[1;32m----> 5\u001B[1;33m                                                   multitiff_files=points_input)\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_data_xr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfovs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Overlaying the DNA\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'points_input' is not defined"
     ]
    }
   ],
   "source": [
    "# Both channels and Point8\n",
    "\n",
    "# Get input for overlay\n",
    "input_data_xr = load_utils.load_imgs_from_multitiff(deepcell_input_dir,\n",
    "                                                  multitiff_files=points_input)\n",
    "print(input_data_xr.fovs.values)\n",
    "# Overlaying the DNA\n",
    "overlay_channels = input_data_xr.channels.values\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "segmentation_utils.visualize_segmentation(\n",
    "            segmentation_labels_xr=segmentation_labels,\n",
    "            fovs=input_data_xr.fovs.values, channel_data_xr=input_data_xr,\n",
    "            chan_list = overlay_channels, output_dir=viz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Channel 0 and Point 8\n",
    "\n",
    "overlay_channels = input_data_xr.channels.values\n",
    "print(input_data_xr[:,:,:,0].fovs.values)\n",
    "print(overlay_channels[0])\n",
    "\n",
    "segmentation_utils.visualize_segmentation(\n",
    "            segmentation_labels_xr=segmentation_labels,\n",
    "            fovs=input_data_xr[:,:,:,0].fovs.values, channel_data_xr=input_data_xr,\n",
    "            chan_list = overlay_channels[0], output_dir=viz_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Channel 1 and Point 8\n",
    "\n",
    "overlay_channels = input_data_xr.channels.values\n",
    "\n",
    "segmentation_utils.visualize_segmentation(\n",
    "            segmentation_labels_xr=segmentation_labels,\n",
    "            fovs=input_data_xr[:,:,:,1].fovs.values, channel_data_xr=input_data_xr,\n",
    "            chan_list = overlay_channels[1], output_dir=viz_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Both Channels, 2 Point 8s\n",
    "\n",
    "overlay_channels = input_data_xr.channels.values\n",
    "extra = input_data_xr.fovs.values\n",
    "print(extra.shape)\n",
    "print(np.concatenate([extra, extra]))\n",
    "print(np.concatenate([extra, extra]).shape)\n",
    "print(overlay_channels.shape)\n",
    "#print(np.concatenate([overlay_channels, overlay_channels[0]]).shape)\n",
    "segmentation_utils.visualize_segmentation(\n",
    "            segmentation_labels_xr=segmentation_labels,\n",
    "            fovs=np.concatenate([extra, input_data_xr[:,:,:,0].fovs.values]),\n",
    "    channel_data_xr=input_data_xr,\n",
    "            chan_list = overlay_channels,\n",
    "    output_dir=viz_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards, we can generate expression matrices from the labeling + imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns:\n",
    "* cell_size_normalized_data: computed by dividing the marker counts in segmentation_labels by their corresponding cell size.\n",
    "* arcsinh_transformed_data: first, linearly scale each value of cell_size_normalized_data by multiplying by 100. Then, pass the linearly scaled cell_size_normalized_data through the arcsinh function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given it's own folder and all fovs having the same channels\n",
    "combined_cell_size_normalized_data, combined_arcsinh_transformed_data = \\\n",
    "    marker_quantification.generate_cell_data(segmentation_labels=segmentation_labels,\n",
    "                                             tiff_dir=tiff_dir,\n",
    "                                             img_sub_folder=\"TIFs\",\n",
    "                                             is_mibitiff=MIBItiff,\n",
    "                                             fovs=fovs,\n",
    "                                             batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path to the single_cell_output folder, and create it if it doesn't already exist\n",
    "# this is where we will store our combined_normalized_data and combined_transformed_data output\n",
    "single_cell_dir = os.path.join(base_dir, \"single_cell_output\")\n",
    "\n",
    "if not os.path.exists(single_cell_dir):\n",
    "    os.makedirs(single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output as CSV\n",
    "combined_cell_size_normalized_data.to_csv(os.path.join(single_cell_dir, 'cell_size_normalized_data.csv'), index=False)\n",
    "combined_arcsinh_transformed_data.to_csv(os.path.join(single_cell_dir, 'arcsinh_transformed_data.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}