{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a notebook for running spatial analysis on paired FOVs and cell tables generated via the `Segment_Image_Data.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ark.utils import spatial_analysis_utils, io_utils, plot_utils, load_utils\n",
    "from ark.analysis import spatial_analysis, visualize\n",
    "\n",
    "import ark.settings as settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes a cell expression matrix, label maps for the fovs to be included in the analysis, and, depending\n",
    "# on the analysis, a threshold matrix for channel or cluster spatial analysis. In channel spatial analysis, cells for\n",
    "# a specific fov are identified, and cells of particular phenotypes are compared to each other to check for positive,\n",
    "# negative, or no enrichment. To do this, a distance matrix is created from the label_maps, cell phenotypes are\n",
    "# identified by their labels in the image and then significant interactions between different populations of phenotypes\n",
    "# are recorded. Similar analysis is also done for channel spatial enrichment; however, instead of looking at cell\n",
    "# phenotypes, markers positive for specific thresholds are identified and specific interactions are then characterized\n",
    "# between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths and import data\n",
    "base_dir = \"../data/example_dataset/\"\n",
    "spatial_analysis_dir = os.path.join(base_dir, \"spatial_enrichment_input_data\")\n",
    "deepcell_output = os.path.join(spatial_analysis_dir, \"deepcell_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate file paths (add other directories as needed)\n",
    "io_utils.validate_paths([\n",
    "    base_dir,\n",
    "    spatial_analysis_dir,\n",
    "    deepcell_output,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in generated cell tables from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary data\n",
    "# This is the cell expression matrix including data for fovs 6 and 7, their cell labels, marker expression,\n",
    "# cell phenotypes, and cell phenotype IDs.\n",
    "all_data = pd.read_csv(os.path.join(spatial_analysis_dir, \"example_expression_matrix.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading user specified marker thresholds from csv file\n",
    "\n",
    "If you're only trying to look at cluster based spatial analysis, you may skip this step.\n",
    "\n",
    "Support for programmatic generation of marker thresholds may be available in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the threshold matrix with all marker thresholds - for channel cpatial enrichment\n",
    "marker_thresholds = pd.read_csv(os.path.join(spatial_analysis_dir, \"markerThresholds.csv\"))\n",
    "marker_thresholds = marker_thresholds.drop(0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in segmentation labels and constructing distance matrices\n",
    "\n",
    "If you're using the legacy `.xr` data format, you will have to load in the file via:\n",
    "```\n",
    "label_maps = xr.load_dataarray(path_to_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Xarray of label maps for multiple fovs from which the distance matrix will be computed\n",
    "#label_maps = xr.load_dataarray(os.path.join(spatial_analysis_dir, \"segmentation_labels.xr\"))\n",
    "label_maps = load_utils.load_imgs_from_dir(deepcell_output, xr_channel_names=['segmentation_label'], match_substring='_feature_0', trim_suffix='_feature_0')\n",
    "\n",
    "# Get dictionary object with the respective distance matrices for the fovs\n",
    "dist_mats = spatial_analysis_utils.calc_dist_matrix(label_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels excluded from spatial analysis\n",
    "\n",
    "These will generally be non biologically significant channels, or channels which won't posess\n",
    "interesting spatial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_channels = [\n",
    "    \"C\",\n",
    "    \"Na\",\n",
    "    \"Si\",\n",
    "    \"Background\",\n",
    "    \"HH3\",\n",
    "    \"Ta\",\n",
    "    \"Au\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute spatial enrichment for channel expression in cells\n",
    "\n",
    "If you're not interested in channel expression, or don't have marker thresholds, continue to the\n",
    "below step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_channel, stats_channel = spatial_analysis.batch_channel_spatial_enrichment(\n",
    "    deepcell_output, marker_thresholds, all_data, excluded_channels=excluded_channels,\n",
    "    bootstrap_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For channel spatial analysis, first find all the marker titles to use as input for the clustergram\n",
    "channel_start = np.where(all_data.columns == settings.PRE_CHANNEL_COL)[0][0] + 1\n",
    "channel_end = np.where(all_data.columns == settings.POST_CHANNEL_COL)[0][0]\n",
    "\n",
    "marker_titles = all_data.iloc[:, channel_start:channel_end].drop(excluded_channels, axis=1).columns\n",
    "visualize.draw_heatmap(stats_channel.loc['fov6', \"z\", :, :].values, marker_titles, marker_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute spatial enrichment for cluster identity of cells\n",
    "\n",
    "If you don't have cluster data, skip this step.  A cell clustering notebook will be released\n",
    "shortly to fascilitate this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_cluster, stats_cluster = spatial_analysis.batch_cluster_spatial_enrichment(\n",
    "    deepcell_output, all_data, bootstrap_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the z scores, a clustermap can be produced\n",
    "# For cluster spatial analysis, first find all the cell phenotypes in the data to use as an input for the clustergram\n",
    "pheno_titles = all_data[\"cell_type\"].drop_duplicates()\n",
    "visualize.draw_heatmap(stats_cluster.loc['fov6', \"z\", :, :].values, pheno_titles, pheno_titles)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
