{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook takes the output of deepcell, processes it, segments cells, and outputs the extracted channel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from segmentation.utils import data_utils, segmentation_utils\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is currently configured as a template to run with the provided example data. If running your own data, make a copy of this notebook first before modifying it.                         Go to file-> make a copy to create a copy of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up filepaths\n",
    "\n",
    "# this folder has the output of the deepcell network\n",
    "base_dir = '../data/example_dataset/'\n",
    "\n",
    "# these don't need to be changed\n",
    "base_name = \"deepcell_output\"\n",
    "deepcell_dir = os.path.join(base_dir, base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The output of the deepcell network is first smoothed to avoid oversplitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for data extraction\n",
    "# the amount of smoothing that will be applied to watershed image\n",
    "pixel_smooth = [4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the data using the thresholds specified above\n",
    "pixel_xr_data = xr.load_dataarray(os.path.join(deepcell_dir, base_name + \"_pixel.xr\"))\n",
    "pixel_xr_data.name = base_name + \"_pixel\"\n",
    "data_utils.save_deepcell_tifs(pixel_xr_data, save_path=deepcell_dir,  transform='pixel', pixel_smooth=pixel_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed deepcell output\n",
    "pixel_xr = xr.load_dataarray(os.path.join(deepcell_dir, '{}_pixel_processed.xr'.format(base_name)))\n",
    "input_xr = xr.load_dataarray(os.path.join(base_dir, \"input_data/deepcell_input.xr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then plot specific points, and look at the smoothing, to assess which is performing the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select point and smooth value to visualize\n",
    "point = \"Point8\"\n",
    "smooth = \"pixel_interior_smoothed_8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "plt.imshow(pixel_xr.loc[point, :, :, smooth])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a few key tunable parameters for performing watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the value that the deepcell probability mask is thresholded at to differentiate cell vs background.\n",
    "# lower values will include more pixels, higher values less\n",
    "background_threshold = 0.35\n",
    "\n",
    "# this is the pixel smooth that was selected from above\n",
    "pixel_smooth = 6\n",
    "\n",
    "# these are the channels that will plotted to assess segmentation accuracy; change to match your dataset\n",
    "# channels within their own bracket will be plotted by themselves. Multiple channels will get plotted together\n",
    "overlay_channels = [[\"HH3\"], [\"Membrane\"], [\"HH3\", \"Membrane\"]]\n",
    "\n",
    "# if you're doing whole-cell prediction, set this to None. If you're doing nuclear prediction, set a single value\n",
    "nuclear_expansion=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then segment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dir = base_dir + \"/segmentation_output_threshold_{}_smooth_{}_expansion_{}/\".format(background_threshold, pixel_smooth, nuclear_expansion)\n",
    "if not os.path.isdir(segmentation_dir):\n",
    "    os.makedirs(segmentation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed over the processed deepcell output\n",
    "segmentation_utils.watershed_transform(pixel_xr=pixel_xr, channel_xr=input_xr, \n",
    "                                       background_threshold=background_threshold,\n",
    "                                       pixel_smooth=\"pixel_interior_smoothed_{}\".format(pixel_smooth),\n",
    "                                       overlay_channels=overlay_channels, output_dir=segmentation_dir, \n",
    "                                       rescale_factor=1.5, nuclear_expansion=nuclear_expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segmentation generated by watershed\n",
    "segmentation_labels = xr.load_dataarray(os.path.join(segmentation_dir,\n",
    "                                                     '{}_pixel_processed_segmentation_labels.xr'.format(base_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then visualize the segmented mask generated by the watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = \"Point8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "plt.imshow(segmentation_labels.loc[point, :, :, \"segmentation_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also visualize the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "plt.imshow(plt.imread(os.path.join(segmentation_dir, \"Point8_{}_overlay.tiff\".format(overlay_channels[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you're happy with the segmentation parameters, we extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading your own dataset, make sure all imaging data is in the same folder, with each FOV given it's own folder\n",
    "# All FOVs must have the same channels\n",
    "\n",
    "# If the TIFs are in a subfolder, specify the name here\n",
    "tif_folder = 'TIFs'\n",
    "\n",
    "# load channel data\n",
    "points_folder = os.path.join(base_dir, \"Input_Data\")\n",
    "points = os.listdir(points_folder)\n",
    "points = [point for point in points if os.path.isdir(os.path.join(points_folder, point))]\n",
    "\n",
    "single_cell_dir = base_dir + \"single_cell_output_threshold_{}_smooth_{}_expansion_{}\".format(background_threshold, pixel_smooth, nuclear_expansion)\n",
    "\n",
    "if not os.path.exists(single_cell_dir):\n",
    "    os.makedirs(single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading more data than can fit into memory at once, we loop through in smaller increments\n",
    "batch_size = 5\n",
    "cohort_len = len(points)\n",
    "num_batch = int(np.floor(cohort_len / batch_size))\n",
    "\n",
    "for i in range(num_batch):\n",
    "    current_points = points[i * batch_size:(i + 1) * batch_size]\n",
    "    image_data = data_utils.load_tifs_from_points_dir(point_dir=points_folder, tif_folder=tif_folder, \n",
    "                                                      points=current_points)\n",
    "    current_labels = segmentation_labels.loc[current_points, :, :, :]\n",
    "    \n",
    "    # segment the imaging data\n",
    "    segmentation_utils.extract_single_cell_data(segmentation_labels=current_labels, image_data=image_data,\n",
    "                                              save_dir=single_cell_dir)\n",
    "\n",
    "# if batch did not divide evenly into total, process remainder\n",
    "if cohort_len % batch_size != 0:\n",
    "    current_points = points[num_batch * batch_size:]\n",
    "    image_data = data_utils.load_tifs_from_points_dir(point_dir=points_folder, tif_folder=tif_folder, \n",
    "                                                      points=current_points)\n",
    "    current_labels = segmentation_labels.loc[current_points, :, :, :]\n",
    "    \n",
    "    # segment the imaging data\n",
    "    segmentation_utils.extract_single_cell_data(segmentation_labels=current_labels, image_data=image_data,\n",
    "                                              save_dir=single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine CSV files together\n",
    "csv_files = os.listdir(single_cell_dir)\n",
    "csv_files = [x for x in csv_files if 'transformed' in x]\n",
    "\n",
    "segmentation_utils.concatenate_csv(base_dir=single_cell_dir, csv_files=csv_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
