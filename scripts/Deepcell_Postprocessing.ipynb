{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook takes the output of deepcell, processes it, segments cells, and outputs the extracted channel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from segmentation.utils import data_utils, segmentation_utils\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is currently configured as a template to run with the provided example data. If running your own data, make a copy of this notebook first before modifying it. If you change this script you'll get merge conflicts when updating to the latest version. Go to file-> make a copy to create a copy of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up file paths\n",
    "base_dir = '../data/example_dataset/'\n",
    "deepcell_dir = os.path.join(base_dir, \"deepcell_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the appropriate files\n",
    "model_output = xr.load_dataarray(os.path.join(deepcell_dir, \"deepcell_output.xr\"))\n",
    "input_xr = xr.load_dataarray(os.path.join(base_dir, \"input_data/Deepcell_Input.xr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a few key tunable parameters for performing watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the value that the deepcell probability mask is thresholded at to differentiate cell vs background.\n",
    "# lower values will include more pixels, higher values less\n",
    "interior_threshold = 0.35\n",
    "\n",
    "# this is the amount that the image will be smoothed; more smoothing results in fewer splits but more merges\n",
    "smooth = 8\n",
    "\n",
    "# these are the channels that will plotted to assess segmentation accuracy; change to match your dataset\n",
    "# channels within their own bracket will be plotted by themselves. Multiple channels will get plotted together\n",
    "overlay_channels = [[\"HH3\"], [\"Membrane\"], [\"HH3\", \"Membrane\"]]\n",
    "\n",
    "# if you're doing whole-cell prediction, set this to None. If you're doing nuclear prediction, set a single value\n",
    "nuclear_expansion=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then segment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dir = base_dir + \"/segmentation_output_threshold_{}_smooth_{}_expansion_{}/\".format(interior_threshold, smooth, nuclear_expansion)\n",
    "if not os.path.isdir(segmentation_dir):\n",
    "    os.makedirs(segmentation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed over the processed deepcell output\n",
    "segmentation_utils.watershed_transform(model_output=model_output, channel_xr=input_xr, \n",
    "                                       overlay_channels=overlay_channels,\n",
    "                                       output_dir=segmentation_dir,\n",
    "                                       interior_threshold=interior_threshold,\n",
    "                                       maxima_smooth=smooth, interior_smooth=smooth,\n",
    "                                        nuclear_expansion=nuclear_expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then visualize the segmented mask generated by the watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segmentation generated by watershed\n",
    "segmentation_labels = xr.load_dataarray(os.path.join(segmentation_dir,\n",
    "                                                     'segmentation_labels.xr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "plt.imshow(segmentation_labels.loc[\"Point8\", :, :, \"segmentation_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also visualize the segmented mask overlaid on the imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13, 13))\n",
    "plt.imshow(plt.imread(os.path.join(segmentation_dir, \"Point8_HH3_Membrane_overlay.tiff\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you're happy with the segmentation parameters, we extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading your own dataset, make sure all imaging data is in the same folder, with each FOV given it's own folder\n",
    "# All FOVs must have the same channels\n",
    "\n",
    "# If the TIFs are in a subfolder, specify the name here\n",
    "img_sub_folder = 'TIFs'\n",
    "\n",
    "# load channel data\n",
    "points_folder = os.path.join(base_dir, \"input_data\")\n",
    "points = os.listdir(points_folder)\n",
    "points = [point for point in points if os.path.isdir(os.path.join(points_folder, point))]\n",
    "points.sort()\n",
    "\n",
    "single_cell_dir = base_dir + \"single_cell_output_threshold_{}_smooth_{}_expansion_{}\".format(interior_threshold, smooth, nuclear_expansion)\n",
    "\n",
    "if not os.path.exists(single_cell_dir):\n",
    "    os.makedirs(single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading more data than can fit into memory at once, we loop through in smaller increments\n",
    "batch_size = 5\n",
    "cohort_len = len(points)\n",
    "num_batch = int(np.floor(cohort_len / batch_size))\n",
    "\n",
    "for i in range(num_batch):\n",
    "    current_points = points[i * batch_size:(i + 1) * batch_size]\n",
    "    image_data = data_utils.load_imgs_from_dir(data_dir=points_folder, img_sub_folder=img_sub_folder, \n",
    "                                                      fovs=current_points)\n",
    "    current_labels = segmentation_labels.loc[current_points, :, :, :]\n",
    "    \n",
    "    # segment the imaging data\n",
    "    segmentation_utils.extract_single_cell_data(segmentation_labels=current_labels, image_data=image_data,\n",
    "                                              save_dir=single_cell_dir)\n",
    "\n",
    "# if batch did not divide evenly into total, process remainder\n",
    "if cohort_len % batch_size != 0:\n",
    "    current_points = points[num_batch * batch_size:]\n",
    "    image_data = data_utils.load_imgs_from_dir(data_dir=points_folder, img_sub_folder=img_sub_folder, \n",
    "                                                      fovs=current_points)\n",
    "    current_labels = segmentation_labels.loc[current_points, :, :, :]\n",
    "    \n",
    "    # segment the imaging data\n",
    "    segmentation_utils.extract_single_cell_data(segmentation_labels=current_labels, image_data=image_data,\n",
    "                                              save_dir=single_cell_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine CSV files together\n",
    "csv_files = os.listdir(single_cell_dir)\n",
    "csv_files = [x for x in csv_files if 'transformed' in x]\n",
    "\n",
    "segmentation_utils.concatenate_csv(base_dir=single_cell_dir, csv_files=csv_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
